{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de81250",
   "metadata": {},
   "source": [
    "# # Phase 2: Story2Audio Pipeline\n",
    "\n",
    "This notebook implements the Story2Audio pipeline for Phase 2 of the NLP project. It:\n",
    "- Preprocesses a story into chunks.\n",
    "- Enhances chunks using tiiuae/falcon-rw-1b locally.\n",
    "- Generates audio using hexgrad/Kokoro-82M locally.\n",
    "- Stitches audio into a final .mp3 file.\n",
    "\n",
    "**Requirements**:\n",
    "- Python 3.11\n",
    "- FFmpeg installed and added to PATH\n",
    "- Dependencies: transformers, torch, kokoro, pydub, soundfile\n",
    "- Hardware: CPU (GPU recommended for faster inference)\n",
    "\n",
    "**Output**: outputs/final_story.mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c383411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.4\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n",
    "print(np.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6e3c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Semester 8\\NLP\\Project\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from src.preprocess import chunk_story\n",
    "from src.enhancer_local import StoryEnhancer\n",
    "from src.kokoro_tts import text_to_coqui_audio\n",
    "from src.utils import combine_audio\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af10960c",
   "metadata": {},
   "source": [
    "# # Step 1: Load and Chunk Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ab63b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:✅Story loaded successfully\n",
      "INFO:__main__:✅Story split into 1 chunks\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load sample story\n",
    "    with open('sample_story.txt', 'r', encoding='utf-8') as f:\n",
    "        story_text = f.read()\n",
    "    logger.info('✅Story loaded successfully')\n",
    "\n",
    "    # Chunk story (~150 words per chunk)\n",
    "    chunks = chunk_story(story_text, chunk_size=150)\n",
    "    logger.info(f'✅Story split into {len(chunks)} chunks')\n",
    "except Exception as e:\n",
    "    logger.error(f'Error in preprocessing: {e}')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f851aba",
   "metadata": {},
   "source": [
    "# # Step 2: Enhance Chunks with tiiuae/falcon-rw-1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c5b74eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Semester 8\\NLP\\Project\\venv\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "Device set to use cpu\n",
      "INFO:src.enhancer_local:Initialized StoryEnhancer locally with model: tiiuae/falcon-rw-1b\n",
      "INFO:__main__:✅StoryEnhancer initialized Locally\n",
      "INFO:src.enhancer_local:Tokenized input length: 164 tokens\n",
      "INFO:__main__:✅Enhanced chunk 1/1\n",
      "INFO:__main__:✅Enhanced chunks saved to enhanced_chunks.txt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Initialize enhancer\n",
    "    enhancer = StoryEnhancer()\n",
    "    logger.info('✅StoryEnhancer initialized Locally')\n",
    "\n",
    "    # Enhance each chunk\n",
    "    enhanced_chunks = []\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        enhanced = enhancer.enhance_chunk(chunk)\n",
    "        enhanced_chunks.append(enhanced)\n",
    "        logger.info(f'✅Enhanced chunk {idx + 1}/{len(chunks)}')\n",
    "\n",
    "    # Save enhanced chunks to a file\n",
    "    with open('enhanced_chunks.txt', 'w', encoding='utf-8') as f:\n",
    "        for chunk in enhanced_chunks:\n",
    "            f.write(chunk + '\\n')\n",
    "    logger.info('✅Enhanced chunks saved to enhanced_chunks.txt')\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f'Error in enhancement: {e}')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62575db",
   "metadata": {},
   "source": [
    "# # Step 3: Generate Audio with Kokoro_tts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10b4437f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:✅Read 1 enhanced chunks from enhanced_chunks.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Defaulting repo_id to hexgrad/Kokoro-82M. Pass repo_id='hexgrad/Kokoro-82M' to suppress this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Semester 8\\NLP\\Project\\venv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "d:\\Semester 8\\NLP\\Project\\venv\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "INFO:src.kokoro_tts:Generated audio for chunk 1 - Graphemes: Once upon a time, Lila wandered through the forest alone because her father, the king, had come home late that night. When he returned home the next day, he brought her father-in-law a beautiful golden box, which he, Phonemes: wˈʌns əpˈɑn ɐ tˈIm, lˈilə wˈɑndəɹd θɹu ðə fˈɔɹəst əlˈOn bəkˈʌz hɜɹ fˈɑðəɹ, ðə kˈɪŋ, hæd kˈʌm hˈOm lˈAt ðˈæt nˈIt. wˌɛn hi ɹətˈɜɹnd hˈOm ðə nˈɛkst dˈA, hi bɹˈɔt hɜɹ fˈɑðəɹənlˌɔ ɐ bjˈuTəfəl ɡˈOldən bˈɑks, wˌɪʧ hi\n",
      "INFO:src.kokoro_tts:Audio saved to outputs/temp/chunk_0.wav\n",
      "INFO:__main__:✅Generated audio files: ['outputs/temp/chunk_0.wav']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Read enhanced chunks from file\n",
    "    with open('enhanced_chunks.txt', 'r', encoding='utf-8') as f:\n",
    "        enhanced_chunks = [line.strip() for line in f if line.strip()]\n",
    "    logger.info(f'✅Read {len(enhanced_chunks)} enhanced chunks from enhanced_chunks.txt')\n",
    "\n",
    "    os.makedirs('outputs/temp', exist_ok=True)\n",
    "    audio_files = text_to_coqui_audio(enhanced_chunks, output_dir='outputs/temp')\n",
    "    logger.info(f'✅Generated audio files: {audio_files}')\n",
    "except Exception as e:\n",
    "    logger.error(f'Error in audio generation: {e}')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebe2239",
   "metadata": {},
   "source": [
    "# # Step 4: Stitch Audio into Final MP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e81ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.utils:Audio stitched and saved to outputs/final_story.mp3\n",
      "INFO:__main__:✅Audio generated: outputs/final_story.mp3\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Combine audio files\n",
    "    output_path = 'outputs/final_story.mp3'\n",
    "    combine_audio(audio_files, output_path)\n",
    "    logger.info(f'✅Audio generated: {output_path}')\n",
    "except Exception as e:\n",
    "    logger.error(f'Error in audio stitching: {e}')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f32338",
   "metadata": {},
   "source": [
    "# # Step 5: Verify Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "255830c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:✅ Verification: Final audio file exists and is playable\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(output_path):\n",
    "    logger.info('✅ Verification: Final audio file exists and is playable')\n",
    "else:\n",
    "    logger.error('❌ Verification: Final audio file not found')\n",
    "    raise FileNotFoundError(f'Output file {output_path} not found')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
